# ============================================================================
# MSI AI Assistant - Environment Variables Template
# ============================================================================
# Copy this file to .env and fill in your API keys
# IMPORTANT: Read RATE_LIMITING_GUIDE.md to set up budget controls!
# ============================================================================

# ----------------------------------------------------------------------------
# REQUIRED: LLM Provider API Keys (choose at least one)
# ----------------------------------------------------------------------------

# OpenAI API Key (recommended for production)
# Get your key: https://platform.openai.com/api-keys
# Cost: GPT-4o-mini = $0.15/1M input tokens (very affordable)
OPENAI_API_KEY=your-openai-api-key-here

# Anthropic API Key (for Claude models)
# Get your key: https://console.anthropic.com/settings/keys
# Cost: Claude 3.5 Sonnet = $3.00/1M input tokens
# ANTHROPIC_API_KEY=your-anthropic-key-here

# Google Gemini API Key (free tier available but limited)
# Get your key: https://makersuite.google.com/app/apikey
# Warning: Free tier has strict rate limits - not recommended for production
# GOOGLE_API_KEY=your-google-api-key-here

# ----------------------------------------------------------------------------
# ⚠️ CRITICAL: Set OpenAI Monthly Budget to Prevent Overspending! ⚠️
# ----------------------------------------------------------------------------
# 1. Go to: https://platform.openai.com/settings/organization/billing/overview
# 2. Click "Usage limits"
# 3. Set "Monthly budget" to $10-50 (recommended starting point)
# 4. Set "Email notification threshold" at 80%
# 5. Monitor usage: https://platform.openai.com/usage
#
# Without a budget cap, you risk unexpected charges if heavily used!
# See RATE_LIMITING_GUIDE.md for detailed cost estimation.
# ----------------------------------------------------------------------------

# ----------------------------------------------------------------------------
# OPTIONAL: LangSmith Tracing (for debugging and monitoring)
# ----------------------------------------------------------------------------

# LangSmith enables detailed tracing and debugging of LLM calls
# Get your API key: https://smith.langchain.com/settings
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=your-langsmith-api-key-here
# LANGCHAIN_PROJECT=msi-ai-assistant

# ----------------------------------------------------------------------------
# Built-in Rate Limiting (configured in code - see RATE_LIMITING_GUIDE.md)
# ----------------------------------------------------------------------------
# The following protections are active by default:
# - Client-side rate limiter: 2 requests/second (120 RPM)
# - Tool call limit: 15 tool calls per query
# - Agentic RAG: Only retrieves docs when needed
#
# To adjust these limits, edit src/main.py and src/api_server.py
# See RATE_LIMITING_GUIDE.md for instructions
# ----------------------------------------------------------------------------
